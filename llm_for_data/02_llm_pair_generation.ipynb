{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import json\n",
    "from typing import List, Optional\n",
    "\n",
    "from ollama import chat\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>vector</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_tsne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>871e39f3-ad80-413d-9353-93b39da8adf5</td>\n",
       "      <td>aa4c9403-c960-442a-aca3-31ad8ae64f6e</td>\n",
       "      <td>[-0.06531426, 0.0017810601, 0.0071745906, -0.0...</td>\n",
       "      <td>## Concept\\n\\nA data connector (aka `Reader`) ...</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"871e39f3-ad80-413d...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>45e0ab38-6280-4862-be9f-b57ce7f96492</td>\n",
       "      <td>5f858553-f1ec-4828-88df-b6dce5754a75</td>\n",
       "      <td>[-0.07814654, -0.0054140342, 0.03389499, -0.05...</td>\n",
       "      <td>## Relation-Based Node Parsers</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"45e0ab38-6280-4862...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>a65609e2-2297-447c-8779-cc312612f445</td>\n",
       "      <td>dc1397d8-b136-4894-91a1-e292a39b15c2</td>\n",
       "      <td>[-0.078950115, -0.04367002, 0.023431662, -0.01...</td>\n",
       "      <td>## LlamaIndex Ecosystem\\n\\nThere's more to the...</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"a65609e2-2297-447c...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>d8e50d48-3935-4a1d-8387-c5f2fd504656</td>\n",
       "      <td>7359399a-1e56-4443-9a70-fc33645355e2</td>\n",
       "      <td>[-0.08533687, -0.019117128, 0.01595358, 0.0007...</td>\n",
       "      <td>## Additional Resources\\n\\n- [A Guide to Extra...</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"d8e50d48-3935-4a1d...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>cd3836ad-9707-4411-90a9-12c1f5d7ae44</td>\n",
       "      <td>84e9995b-6686-49f4-82ca-c207dd25900e</td>\n",
       "      <td>[-0.10055203, -0.034588337, -0.016951276, -0.0...</td>\n",
       "      <td>## Usage\\n\\nYou can create an index on LlamaCl...</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"cd3836ad-9707-4411...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  \\\n",
       "783   871e39f3-ad80-413d-9353-93b39da8adf5   \n",
       "851   45e0ab38-6280-4862-be9f-b57ce7f96492   \n",
       "600   a65609e2-2297-447c-8779-cc312612f445   \n",
       "1432  d8e50d48-3935-4a1d-8387-c5f2fd504656   \n",
       "746   cd3836ad-9707-4411-90a9-12c1f5d7ae44   \n",
       "\n",
       "                                    doc_id  \\\n",
       "783   aa4c9403-c960-442a-aca3-31ad8ae64f6e   \n",
       "851   5f858553-f1ec-4828-88df-b6dce5754a75   \n",
       "600   dc1397d8-b136-4894-91a1-e292a39b15c2   \n",
       "1432  7359399a-1e56-4443-9a70-fc33645355e2   \n",
       "746   84e9995b-6686-49f4-82ca-c207dd25900e   \n",
       "\n",
       "                                                 vector  \\\n",
       "783   [-0.06531426, 0.0017810601, 0.0071745906, -0.0...   \n",
       "851   [-0.07814654, -0.0054140342, 0.03389499, -0.05...   \n",
       "600   [-0.078950115, -0.04367002, 0.023431662, -0.01...   \n",
       "1432  [-0.08533687, -0.019117128, 0.01595358, 0.0007...   \n",
       "746   [-0.10055203, -0.034588337, -0.016951276, -0.0...   \n",
       "\n",
       "                                                   text  \\\n",
       "783   ## Concept\\n\\nA data connector (aka `Reader`) ...   \n",
       "851                      ## Relation-Based Node Parsers   \n",
       "600   ## LlamaIndex Ecosystem\\n\\nThere's more to the...   \n",
       "1432  ## Additional Resources\\n\\n- [A Guide to Extra...   \n",
       "746   ## Usage\\n\\nYou can create an index on LlamaCl...   \n",
       "\n",
       "                                               metadata  cluster  cluster_tsne  \n",
       "783   {'_node_content': '{\"id_\": \"871e39f3-ad80-413d...       19             0  \n",
       "851   {'_node_content': '{\"id_\": \"45e0ab38-6280-4862...       15             0  \n",
       "600   {'_node_content': '{\"id_\": \"a65609e2-2297-447c...        7             0  \n",
       "1432  {'_node_content': '{\"id_\": \"d8e50d48-3935-4a1d...        7             0  \n",
       "746   {'_node_content': '{\"id_\": \"cd3836ad-9707-4411...       19             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\n",
    "    './data/eval_sampled.parquet',\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Concept\n",
      "\n",
      "A data connector (aka `Reader`) ingest data from different data sources and data formats into a simple `Document` representation (text and simple metadata).\n",
      "\n",
      "!!! tip\n",
      "    Once you've ingested your data, you can build an [Index](../../indexing/index.md) on top, ask questions using a [Query Engine](../../deploying/query_engine/index.md), and have a conversation using a [Chat Engine](../../deploying/chat_engines/index.md).\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define prompt & response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_prompt_structured(context: str) -> str:\n",
    "    prompt = f\"\"\"You are an expert at creating diverse and challenging Question-Answer pairs from text that \n",
    "will be used to evaluate a Retrieval Augmented Generation system.\n",
    "\n",
    "Given the following document chunk, generate 3 question-answer pairs that mimic realistic questions that \n",
    "a user might ask about this documentation and:\n",
    "\n",
    "1. Include different question types (factual, inferential, analytical)\n",
    "2. Vary in difficulty (basic recall, complex reasoning)\n",
    "3. Test understanding of key concepts, relationships, and implications\n",
    " \n",
    "The questions should be directly answerable from the documentation and should not require any external knowledge.\n",
    "\n",
    "\n",
    "<start documentation>\n",
    "{context}\n",
    "<end documentation>\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTypeEnum(str, Enum):\n",
    "    factual = 'factual'\n",
    "    inferential = 'inferential'\n",
    "    analytical = 'analytical'\n",
    "\n",
    "class DifficultyEnum(str, Enum):\n",
    "    easy = 'easy'\n",
    "    medium = 'medium'\n",
    "    hard = 'hard'\n",
    "\n",
    "class QAQualityEnum(str, Enum):\n",
    "    good = 'good'\n",
    "    fair = 'fair'\n",
    "    poor = 'poor'\n",
    "\n",
    "class QAPairMetaData(BaseModel):\n",
    "    question_type: QTypeEnum = Field(\n",
    "        description=\"Question type\"\n",
    "    )\n",
    "    difficulty: DifficultyEnum = Field(\n",
    "        description=\"Question difficulty\"\n",
    "    )\n",
    "    required_context: str = Field(\n",
    "        description=\"Specific quote string from the chunk needed to answer the question\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"A brief description of how you arrived at the answer from the context\"\n",
    "    )\n",
    "    q_a_quality: QAQualityEnum = Field(\n",
    "        description=\"Your assessment of the quality of the Q-A pair for evaluating a RAG system\"\n",
    "    )\n",
    "\n",
    "\n",
    "class QAPair(BaseModel):\n",
    "    question: str\n",
    "    metadata: QAPairMetaData\n",
    "    answer: str\n",
    "\n",
    "class QAPairList(BaseModel):\n",
    "    qa_pairs: List[QAPair]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert at creating diverse and challenging Question-Answer pairs from text that \n",
      "will be used to evaluate a Retrieval Augmented Generation system.\n",
      "\n",
      "Given the following document chunk, generate 3 question-answer pairs that mimic realistic questions that \n",
      "a user might ask about this documentation and:\n",
      "\n",
      "1. Include different question types (factual, inferential, analytical)\n",
      "2. Vary in difficulty (basic recall, complex reasoning)\n",
      "3. Test understanding of key concepts, relationships, and implications\n",
      " \n",
      "The questions should be directly answerable from the documentation and should not require any external knowledge.\n",
      "\n",
      "\n",
      "<start documentation>\n",
      "## Concept\n",
      "\n",
      "A data connector (aka `Reader`) ingest data from different data sources and data formats into a simple `Document` representation (text and simple metadata).\n",
      "\n",
      "!!! tip\n",
      "    Once you've ingested your data, you can build an [Index](../../indexing/index.md) on top, ask questions using a [Query Engine](../../deploying/query_engine/index.md), and have a conversation using a [Chat Engine](../../deploying/chat_engines/index.md).\n",
      "<end documentation>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ = generate_qa_prompt_structured(df.iloc[0]['text'])\n",
    "print(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama3.1-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_llama = chat(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': input_,\n",
    "    }\n",
    "  ],\n",
    "  model='llama3.1:latest',\n",
    "  format=QAPairList.model_json_schema(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs_llama = QAPairList.model_validate_json(r_llama.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"question\": \"What is the primary function of a data connector in this system?\",\n",
      "        \"metadata\": {\n",
      "            \"question_type\": \"factual\",\n",
      "            \"difficulty\": \"easy\",\n",
      "            \"required_context\": \"concept section\",\n",
      "            \"reasoning\": \" basic recall \",\n",
      "            \"q_a_quality\": \"good\"\n",
      "        },\n",
      "        \"answer\": \"to ingest data from different data sources and data formats\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What kind of document representation is used after ingesting data?\",\n",
      "        \"metadata\": {\n",
      "            \"question_type\": \"factual\",\n",
      "            \"difficulty\": \"medium\",\n",
      "            \"required_context\": \"concept section\",\n",
      "            \"reasoning\": \" basic recall \",\n",
      "            \"q_a_quality\": \"good\"\n",
      "        },\n",
      "        \"answer\": \"a simple Document representation (text and simple metadata)\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What are the potential benefits of building an index on top of ingested data?\",\n",
      "        \"metadata\": {\n",
      "            \"question_type\": \"inferential\",\n",
      "            \"difficulty\": \"hard\",\n",
      "            \"required_context\": \"tip section\",\n",
      "            \"reasoning\": \" complex reasoning\",\n",
      "            \"q_a_quality\": \"good\"\n",
      "        },\n",
      "        \"answer\": \"ask questions using a Query Engine, and have a conversation using a Chat Engine\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(qa_pairs_llama.model_dump()['qa_pairs'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling up LLM size with gemma3-12b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_gemma = chat(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': input_,\n",
    "    }\n",
    "  ],\n",
    "  model='gemma3:12b',\n",
    "  format=QAPairList.model_json_schema(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs_gemma = QAPairList.model_validate_json(r_gemma.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"question\": \"What is a data connector referred to as in this documentation?\",\n",
      "        \"metadata\": {\n",
      "            \"question_type\": \"factual\",\n",
      "            \"difficulty\": \"easy\",\n",
      "            \"required_context\": \"Definition of data connector\",\n",
      "            \"reasoning\": \"Direct recall from the text.\",\n",
      "            \"q_a_quality\": \"good\"\n",
      "        },\n",
      "        \"answer\": \"A data connector is referred to as a 'Reader'.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"After data is ingested, what are the next steps outlined for utilizing the data?\",\n",
      "        \"metadata\": {\n",
      "            \"question_type\": \"inferential\",\n",
      "            \"difficulty\": \"medium\",\n",
      "            \"required_context\": \"Flow of data processing steps\",\n",
      "            \"reasoning\": \"Requires understanding the sequence of actions mentioned \\u2013 ingest, build an index, query, chat.\",\n",
      "            \"q_a_quality\": \"good\"\n",
      "        },\n",
      "        \"answer\": \"After ingesting data, the next steps are to build an Index, use a Query Engine, and utilize a Chat Engine.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Explain the overall purpose of a 'Reader' within this system, relating it to the other components mentioned.\",\n",
      "        \"metadata\": {\n",
      "            \"question_type\": \"analytical\",\n",
      "            \"difficulty\": \"hard\",\n",
      "            \"required_context\": \"Purpose of Reader, relationship to Index, Query and Chat Engines\",\n",
      "            \"reasoning\": \"Requires understanding the Reader's function as the initial step in a larger process, connecting it to subsequent components and their roles.\",\n",
      "            \"q_a_quality\": \"good\"\n",
      "        },\n",
      "        \"answer\": \"A 'Reader', or data connector, serves as the first step in the process. It ingests data from various sources and transforms it into a standardized 'Document' representation. This allows subsequent components, like the Index, Query Engine, and Chat Engine, to work with the data in a consistent format, enabling question answering and conversational interactions.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(qa_pairs_gemma.model_dump()['qa_pairs'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale to all chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expect to take about 0.83 hours\n"
     ]
    }
   ],
   "source": [
    "print(f\"Expect to take about {df.shape[0]*15/(60*60):.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_dataset(\n",
    "    filepath: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str = 'gemma3:12b',\n",
    "    max_evals: Optional[int] = None,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    for col in ['id', 'text']:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "        \n",
    "    with open(filepath, 'w') as f:\n",
    "        for i, (idx, row) in enumerate(df.iterrows()):\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Generating for row {i}\")\n",
    "            input_ = generate_qa_prompt_structured(row['text'])\n",
    "            r = chat(\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': input_,\n",
    "                    }\n",
    "                ],\n",
    "                model=model,\n",
    "                format=QAPairList.model_json_schema(),\n",
    "            )\n",
    "            try:\n",
    "                qa_pairs = QAPairList.model_validate_json(r.message.content)\n",
    "                gen_dict = qa_pairs.model_dump()\n",
    "                gen_dict.update({\n",
    "                    'idx': idx,\n",
    "                    'id': row['id'],\n",
    "                })\n",
    "                out_ = json.dumps(gen_dict)\n",
    "            except:\n",
    "                if verbose:\n",
    "                    print(f\"Failed for row {i}\")\n",
    "                out_ = \"\"\n",
    "            f.write(out_ + '\\n')\n",
    "\n",
    "            if max_evals and i >= max_evals-1:\n",
    "                break\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_filepath = './data/qa_pairs_gemma.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating for row 0\n",
      "Generating for row 1\n",
      "Generating for row 2\n",
      "Generating for row 3\n",
      "Generating for row 4\n",
      "Generating for row 5\n",
      "Generating for row 6\n",
      "Generating for row 7\n",
      "Generating for row 8\n",
      "Generating for row 9\n",
      "Generating for row 10\n",
      "Generating for row 11\n",
      "Generating for row 12\n",
      "Generating for row 13\n",
      "Generating for row 14\n",
      "Generating for row 15\n",
      "Generating for row 16\n",
      "Generating for row 17\n",
      "Generating for row 18\n",
      "Generating for row 19\n",
      "Generating for row 20\n",
      "Generating for row 21\n",
      "Generating for row 22\n",
      "Generating for row 23\n",
      "Generating for row 24\n",
      "Generating for row 25\n",
      "Generating for row 26\n",
      "Generating for row 27\n",
      "Generating for row 28\n",
      "Generating for row 29\n",
      "Generating for row 30\n",
      "Generating for row 31\n",
      "Generating for row 32\n",
      "Generating for row 33\n",
      "Generating for row 34\n",
      "Generating for row 35\n",
      "Generating for row 36\n",
      "Generating for row 37\n",
      "Generating for row 38\n",
      "Generating for row 39\n",
      "Generating for row 40\n",
      "Generating for row 41\n",
      "Generating for row 42\n",
      "Generating for row 43\n",
      "Generating for row 44\n",
      "Generating for row 45\n",
      "Generating for row 46\n",
      "Generating for row 47\n",
      "Generating for row 48\n",
      "Generating for row 49\n",
      "Generating for row 50\n",
      "Generating for row 51\n",
      "Generating for row 52\n",
      "Generating for row 53\n",
      "Generating for row 54\n",
      "Generating for row 55\n",
      "Generating for row 56\n",
      "Generating for row 57\n",
      "Generating for row 58\n",
      "Generating for row 59\n",
      "Generating for row 60\n",
      "Generating for row 61\n",
      "Generating for row 62\n",
      "Generating for row 63\n",
      "Generating for row 64\n",
      "Generating for row 65\n",
      "Generating for row 66\n",
      "Generating for row 67\n",
      "Generating for row 68\n",
      "Generating for row 69\n",
      "Generating for row 70\n",
      "Generating for row 71\n",
      "Generating for row 72\n",
      "Generating for row 73\n",
      "Generating for row 74\n",
      "Generating for row 75\n",
      "Generating for row 76\n",
      "Generating for row 77\n",
      "Generating for row 78\n",
      "Generating for row 79\n",
      "Generating for row 80\n",
      "Generating for row 81\n",
      "Generating for row 82\n",
      "Generating for row 83\n",
      "Generating for row 84\n",
      "Generating for row 85\n",
      "Generating for row 86\n",
      "Generating for row 87\n",
      "Generating for row 88\n",
      "Generating for row 89\n",
      "Generating for row 90\n",
      "Generating for row 91\n",
      "Generating for row 92\n",
      "Generating for row 93\n",
      "Generating for row 94\n",
      "Generating for row 95\n",
      "Generating for row 96\n",
      "Generating for row 97\n",
      "Generating for row 98\n",
      "Generating for row 99\n",
      "Generating for row 100\n",
      "Generating for row 101\n",
      "Generating for row 102\n",
      "Generating for row 103\n",
      "Generating for row 104\n",
      "Generating for row 105\n",
      "Generating for row 106\n",
      "Generating for row 107\n",
      "Generating for row 108\n",
      "Generating for row 109\n",
      "Generating for row 110\n",
      "Generating for row 111\n",
      "Generating for row 112\n",
      "Generating for row 113\n",
      "Generating for row 114\n",
      "Generating for row 115\n",
      "Generating for row 116\n",
      "Generating for row 117\n",
      "Generating for row 118\n",
      "Generating for row 119\n",
      "Generating for row 120\n",
      "Generating for row 121\n",
      "Generating for row 122\n",
      "Generating for row 123\n",
      "Generating for row 124\n",
      "Generating for row 125\n",
      "Generating for row 126\n",
      "Generating for row 127\n",
      "Generating for row 128\n",
      "Generating for row 129\n",
      "Generating for row 130\n",
      "Generating for row 131\n",
      "Generating for row 132\n",
      "Generating for row 133\n",
      "Generating for row 134\n",
      "Generating for row 135\n",
      "Generating for row 136\n",
      "Generating for row 137\n",
      "Generating for row 138\n",
      "Generating for row 139\n",
      "Generating for row 140\n",
      "Generating for row 141\n",
      "Generating for row 142\n",
      "Generating for row 143\n",
      "Generating for row 144\n",
      "Generating for row 145\n",
      "Generating for row 146\n",
      "Generating for row 147\n",
      "Generating for row 148\n",
      "Generating for row 149\n",
      "Generating for row 150\n",
      "Generating for row 151\n",
      "Generating for row 152\n",
      "Generating for row 153\n",
      "Generating for row 154\n",
      "Generating for row 155\n",
      "Generating for row 156\n",
      "Generating for row 157\n",
      "Generating for row 158\n",
      "Generating for row 159\n",
      "Generating for row 160\n",
      "Generating for row 161\n",
      "Generating for row 162\n",
      "Generating for row 163\n",
      "Generating for row 164\n",
      "Generating for row 165\n",
      "Generating for row 166\n",
      "Generating for row 167\n",
      "Generating for row 168\n",
      "Generating for row 169\n",
      "Generating for row 170\n",
      "Generating for row 171\n",
      "Generating for row 172\n",
      "Generating for row 173\n",
      "Generating for row 174\n",
      "Generating for row 175\n",
      "Generating for row 176\n",
      "Generating for row 177\n",
      "Generating for row 178\n",
      "Generating for row 179\n",
      "Generating for row 180\n",
      "Generating for row 181\n",
      "Generating for row 182\n",
      "Generating for row 183\n",
      "Generating for row 184\n",
      "Generating for row 185\n",
      "Generating for row 186\n",
      "Generating for row 187\n",
      "Generating for row 188\n",
      "Generating for row 189\n",
      "Generating for row 190\n",
      "Generating for row 191\n",
      "Generating for row 192\n",
      "Generating for row 193\n",
      "Generating for row 194\n",
      "Generating for row 195\n",
      "Generating for row 196\n",
      "Generating for row 197\n",
      "Generating for row 198\n",
      "Generating for row 199\n"
     ]
    }
   ],
   "source": [
    "generate_qa_dataset(\n",
    "    filepath=eval_filepath,\n",
    "    df=df,\n",
    "    model='gemma3:12b',\n",
    "    max_evals=None,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>vector</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_tsne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>871e39f3-ad80-413d-9353-93b39da8adf5</td>\n",
       "      <td>aa4c9403-c960-442a-aca3-31ad8ae64f6e</td>\n",
       "      <td>[-0.06531426, 0.0017810601, 0.0071745906, -0.0...</td>\n",
       "      <td>## Concept\\n\\nA data connector (aka `Reader`) ...</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"871e39f3-ad80-413d...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>45e0ab38-6280-4862-be9f-b57ce7f96492</td>\n",
       "      <td>5f858553-f1ec-4828-88df-b6dce5754a75</td>\n",
       "      <td>[-0.07814654, -0.0054140342, 0.03389499, -0.05...</td>\n",
       "      <td>## Relation-Based Node Parsers</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"45e0ab38-6280-4862...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>a65609e2-2297-447c-8779-cc312612f445</td>\n",
       "      <td>dc1397d8-b136-4894-91a1-e292a39b15c2</td>\n",
       "      <td>[-0.078950115, -0.04367002, 0.023431662, -0.01...</td>\n",
       "      <td>## LlamaIndex Ecosystem\\n\\nThere's more to the...</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"a65609e2-2297-447c...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>d8e50d48-3935-4a1d-8387-c5f2fd504656</td>\n",
       "      <td>7359399a-1e56-4443-9a70-fc33645355e2</td>\n",
       "      <td>[-0.08533687, -0.019117128, 0.01595358, 0.0007...</td>\n",
       "      <td>## Additional Resources\\n\\n- [A Guide to Extra...</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"d8e50d48-3935-4a1d...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>cd3836ad-9707-4411-90a9-12c1f5d7ae44</td>\n",
       "      <td>84e9995b-6686-49f4-82ca-c207dd25900e</td>\n",
       "      <td>[-0.10055203, -0.034588337, -0.016951276, -0.0...</td>\n",
       "      <td>## Usage\\n\\nYou can create an index on LlamaCl...</td>\n",
       "      <td>{'_node_content': '{\"id_\": \"cd3836ad-9707-4411...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  \\\n",
       "783   871e39f3-ad80-413d-9353-93b39da8adf5   \n",
       "851   45e0ab38-6280-4862-be9f-b57ce7f96492   \n",
       "600   a65609e2-2297-447c-8779-cc312612f445   \n",
       "1432  d8e50d48-3935-4a1d-8387-c5f2fd504656   \n",
       "746   cd3836ad-9707-4411-90a9-12c1f5d7ae44   \n",
       "\n",
       "                                    doc_id  \\\n",
       "783   aa4c9403-c960-442a-aca3-31ad8ae64f6e   \n",
       "851   5f858553-f1ec-4828-88df-b6dce5754a75   \n",
       "600   dc1397d8-b136-4894-91a1-e292a39b15c2   \n",
       "1432  7359399a-1e56-4443-9a70-fc33645355e2   \n",
       "746   84e9995b-6686-49f4-82ca-c207dd25900e   \n",
       "\n",
       "                                                 vector  \\\n",
       "783   [-0.06531426, 0.0017810601, 0.0071745906, -0.0...   \n",
       "851   [-0.07814654, -0.0054140342, 0.03389499, -0.05...   \n",
       "600   [-0.078950115, -0.04367002, 0.023431662, -0.01...   \n",
       "1432  [-0.08533687, -0.019117128, 0.01595358, 0.0007...   \n",
       "746   [-0.10055203, -0.034588337, -0.016951276, -0.0...   \n",
       "\n",
       "                                                   text  \\\n",
       "783   ## Concept\\n\\nA data connector (aka `Reader`) ...   \n",
       "851                      ## Relation-Based Node Parsers   \n",
       "600   ## LlamaIndex Ecosystem\\n\\nThere's more to the...   \n",
       "1432  ## Additional Resources\\n\\n- [A Guide to Extra...   \n",
       "746   ## Usage\\n\\nYou can create an index on LlamaCl...   \n",
       "\n",
       "                                               metadata  cluster  cluster_tsne  \n",
       "783   {'_node_content': '{\"id_\": \"871e39f3-ad80-413d...       19             0  \n",
       "851   {'_node_content': '{\"id_\": \"45e0ab38-6280-4862...       15             0  \n",
       "600   {'_node_content': '{\"id_\": \"a65609e2-2297-447c...        7             0  \n",
       "1432  {'_node_content': '{\"id_\": \"d8e50d48-3935-4a1d...        7             0  \n",
       "746   {'_node_content': '{\"id_\": \"cd3836ad-9707-4411...       19             0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_pairs</th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'question': 'What is the primary function of...</td>\n",
       "      <td>783</td>\n",
       "      <td>871e39f3-ad80-413d-9353-93b39da8adf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'question': 'What is the primary subject mat...</td>\n",
       "      <td>851</td>\n",
       "      <td>45e0ab38-6280-4862-be9f-b57ce7f96492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'question': 'What is the primary function of...</td>\n",
       "      <td>600</td>\n",
       "      <td>a65609e2-2297-447c-8779-cc312612f445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'question': 'What resource is provided to he...</td>\n",
       "      <td>1432</td>\n",
       "      <td>d8e50d48-3935-4a1d-8387-c5f2fd504656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'question': 'What environment variable is us...</td>\n",
       "      <td>746</td>\n",
       "      <td>cd3836ad-9707-4411-90a9-12c1f5d7ae44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            qa_pairs   idx  \\\n",
       "0  [{'question': 'What is the primary function of...   783   \n",
       "1  [{'question': 'What is the primary subject mat...   851   \n",
       "2  [{'question': 'What is the primary function of...   600   \n",
       "3  [{'question': 'What resource is provided to he...  1432   \n",
       "4  [{'question': 'What environment variable is us...   746   \n",
       "\n",
       "                                     id  \n",
       "0  871e39f3-ad80-413d-9353-93b39da8adf5  \n",
       "1  45e0ab38-6280-4862-be9f-b57ce7f96492  \n",
       "2  a65609e2-2297-447c-8779-cc312612f445  \n",
       "3  d8e50d48-3935-4a1d-8387-c5f2fd504656  \n",
       "4  cd3836ad-9707-4411-90a9-12c1f5d7ae44  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse jsonl file\n",
    "df_tmp = pd.read_json(eval_filepath, lines=True)\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
